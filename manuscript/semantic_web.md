# Semantic Web {#semantic-web}

The Semantic Web is intended to provide a massive linked set of data for
use by software systems just as the World Wide Web provides a massive
collection of linked web pages for human reading and browsing. The
Semantic Web is like the web in that anyone can generate any content
that they want. This freedom to publish anything works for the web
because we use our ability to understand natural language to interpret
what we read – and often to dismiss material that based upon our own
knowledge we consider to be incorrect.

The core concept for the Semantic Web is data integration and use from
different sources. As we will soon see, the tools for implementing the
Semantic Web are designed for encoding data and sharing data from many
different sources.

I cover the semantic web in this book because I believe that semantic web technologies are complementary to AI systems for gathering and processing data on the web. As more web web pages are generated by applications (as opposed to simply showing static HTML files) it becomes easier to produce both HTML for human readers and semantic data for software agents.

There are several very good Semantic Web toolkits for the Java language
and platform. I will use Sesame because it is what I often use in my own
work and I believe that it is a good starting technology for your first
experiments with Semantic Web technologies. This chapter provides an
incomplete coverage of Semantic Web technologies and is intended merely
as a gentle introduction to a few useful techniques and how to implement
those techniques in Java. The Jena library is also widely used.

Figure [fig:semantic-web-data-models] shows a layered set of data models that
are used to implement Semantic Web applications. To design and implement
these applications we need to think in terms of physical models (storage
and access of RDF, RDFS, and perhaps OWL data), logical models (how we
use RDF and RDFS to define relationships between data represented as
unique URIs and string literals and how we logically combine data from
different sources) and conceptual modeling (higher level knowledge
representation using OWL).

{#semantic-web-data-models}
![Semantic Web Data Models](images/semantic_web_data.png)

I wrote a separate book *Practical Semantic Web
Programming in Java* that goes into much more detail on the use of
Sesame, Jena, Protege, OwlApis, RDF/RDFS/OWL modeling, and Descriptive
Logic Reasoners. This chapter is meant to get you interested in this
technology but is not intended as a detailed guide. You can get a free PDF of *Practical Semantic Web Programming in Java* on my web site. There is also a version for the Common Lisp language that is also available as a free PDF file.

## Relational Database Model Has Problems Dealing with Rapidly Changing Data Requirements  {#rdms-problems}

When people are first introduced to Semantic Web technologies their
first reaction is often something like, “I can just do that with a
database.” The relational database model is an efficient way to express
and work with slowly changing data models. There are some clever tools
for dealing with data change requirements in the database world
(ActiveRecord and migrations being a good example) but it is awkward to
have end users and even developers tagging on new data attributes to
relational database tables.

This same limitation also applies to object oriented programming and
object modeling. Even with dynamic languages that facilitate modifying
classes at runtime, the options for adding attributes to existing models
is just too limiting. The same argument can be made against the use of
XML constrained by conformance to either DTDs or XML Schemas. It is true
that RDF and RDFS can be serialized to XML using many pre-existing XML
namespaces for different knowledge sources and their schemas but it
turns out that this is done in a way that does not reduce the
flexibility for extending data models. XML storage is really only a
serialization of RDF and many developers who are just starting to use
Semantic Web technologies initially get confused trying to read XML
serialization of RDF – almost like trying to read a PDF file with a
plain text editor and something to be avoided.

A major goal for the rest of this chapter is convincing you that
modeling data with RDF and RDFS facilitates freely extending data models
and also allows fairly easy integration of data from different sources
using different schemas without explicitly converting data from one
schema to another for reuse.

## RDF: The Universal Data Format

The Resource Description Framework (RDF) is used to encode information
and the RDF Schema (RDFS) facilitates using data with different RDF
encodings without the need to convert data formats.

RDF data was originally encoded as XML and intended for automated
processing. In this chapter we will use two simple to read formats
called "N-Triples" and "N3." Sesame can be used to convert between all
RDF formats so we might as well use formats that are easier to read and
understand. RDF data consists of a set of triple values:

-   subject

-   predicate

-   object

Some of my work with Semantic Web technologies deals with processing
news stories, extracting semantic information from the text, and storing
it in RDF. I will use this application domain for the examples in this
chapter. I deal with triples like:

-   subject: a URL (or URI) of a news article

-   predicate: a relation like "containsPerson"

-   object: a value like "Bill Clinton"

As previously mentioned, we will use either URIs or string literals as
values for subjects and objects. We will always use URIs for the values
of predicates. In any case URIs are usually preferred to string literals
because they are unique. We will see an example of this preferred use
but first we need to learn the N-Triple and N3 RDF formats.

In Section [sec:rdms-problems] I proposed the idea that RDF was more
flexible than Object Modeling in programming languages, relational
databases, and XML with schemas. If we can tag new attributes on the fly
to existing data, how do we prevent what I might call “data chaos” as we
modify existing data sources? It turns out that the solution to this
problem is also the solution for encoding real semantics (or meaning)
with data: we usually use unique URIs for RDF subjects, predicates, and
objects, and usually with a preference for not using string literals. I
will try to make this idea more clear with some examples.

Any part of a triple (subject, predicate, or object) is either a URI or
a string literal. URIs encode namespaces. For example, the
containsPerson predicate in the last example could properly be written
as:

    http://knowledgebooks.com/ontology/#containsPerson

The first part of this URI is considered to be the namespace for (what
we will use as a predicate) “containsPerson.” When different RDF triples
use this same predicate, this is some assurance to us that all users of
this predicate subscribe to the same meaning. Furthermore, we will see
in [Section on RDFS](#rdfs) that we can use RDFS to state equivalency between
this predicate (in the namespace http://knowledgebooks.com/ontology/)
with predicates represented by different URIs used in other data
sources. In an “artificial intelligence” sense, software that we write
does not understand a predicate like “containsPerson” in the way that a
human reader can by combining understood common meanings for the words
“contains” and “person” but for many interesting and useful types of
applications that is fine as long as the predicate is used consistently.
We will see shortly that we can define abbreviation prefixes for
namespaces which makes RDF and RDFS files shorter and easier to read.

A statement in N-Triple format consists of three URIs (or string
literals – any combination) followed by a period to end the statement.
While statements are often written one per line in a source file they
can be broken across lines; it is the ending period which marks the end
of a statement. The standard file extension for N-Triple format files is
\*.nt and the standard format for N3 format files is \*.n3.

My preference is to use N-Triple format files as output from programs
that I write to save data as RDF. I often use Sesame to convert N-Triple
files to N3 if I will be reading them or even hand editing them. You
will see why I prefer the N3 format when we look at an example:

    @prefix kb:  <http://knowledgebooks.com/ontology#> .
    <http://news.com/201234 /> kb:containsCountry "China"  .

Here we see the use of an abbreviation prefix “kb:” for the namespace
for my company KnowledgeBooks.com ontologies. The first term in the RDF
statement (the subject) is the URI of a news article. The second term
(the predicate) is “containsCountry” in the “kb:” namespace. The last
item in the statement (the object) is a string literal “China.” I would
describe this RDF statement in English as, “The news article at URI
http://news.com/201234 mentions the country China.”

This was a very simple N3 example which we will expand to show
additional features of the N3 notation. As another example, suppose that
this news article also mentions the USA. Instead of adding a whole new
statement like this:

~~~~~~~~
    @prefix kb:  <http://knowledgebooks.com/ontology#> .
    <http://news.com/201234 /> kb:containsCountry "China"  .
    <http://news.com/201234 /> kb:containsCountry "USA"  .
~~~~~~~~

we can combine them using N3 notation. N3 allows us to collapse multiple
RDF statements that share the same subject and optionally the same
predicate:

~~~~~~~~
    @prefix kb:  <http://knowledgebooks.com/ontology#> .
    <http://news.com/201234 /> kb:containsCountry "China" ,
                                                  "USA" .
~~~~~~~~

We can also add in additional predicates that use the same subject:

~~~~~~~~
    @prefix kb:  <http://knowledgebooks.com/ontology#> .

    <http://news.com/201234 /> kb:containsCountry "China" ,
                                                  "USA" .
        kb:containsOrganization "United Nations" ;
        kb:containsPerson "Ban Ki-moon" , "Gordon Brown" ,
                          "Hu Jintao" , "George W. Bush" ,
                          "Pervez Musharraf" ,
                          "Vladimir Putin" , 
                          "Mahmoud Ahmadinejad" .
~~~~~~~~

This single N3 statement represents ten individual RDF triples. Each
section defining triples with the same subject and predicate have
objects separated by commas and ending with a period. Please note that
whatever RDF storage system we use (we will be using Sesame) it makes no
difference if we load RDF as XML, N-Triple, of N3 format files:
internally subject, predicate, and object triples are stored in the same
way and are used in the same way.

I promised you that the data in RDF data stores was easy to extend. As
an example, let us assume that we have written software that is able to
read online news articles and create RDF data that captures some of the
semantics in the articles. If we extend our program to also recognize
dates when the articles are published, we can simply reprocess articles
and for each article add a triple to our RDF data store using a form
like:

~~~~~~~~
    <http://news.com/201234 /> kb:datePublished
                               "2008-05-11" .
~~~~~~~~

Furthermore, if we do not have dates for all news articles that is often
acceptable depending on the application.

## Extending RDF with RDF Schema {#rdfs}

RDFS supports the definition of classes and properties based on set
inclusion. In RDFS classes and properties are orthogonal. We will not
simply be using properties to define data attributes for classes – this
is different than object modeling and object oriented programming
languages like Java. RDFS is encoded as RDF – the same syntax.

Because the Semantic Web is intended to be processed automatically by
software systems it is encoded as RDF. There is a problem that must be
solved in implementing and using the Semantic Web: everyone who
publishes Semantic Web data is free to create their own RDF schemas for
storing data; for example, there is usually no single standard RDF
schema definition for topics like news stories and stock market data.
Understanding the difficulty of integrating different data sources in
different formats helps to understand the design decisions behind the
Semantic Web.

We will start with an example that is an extension of the example in the
last section that also uses RDFS. We add a few additional RDF statements
(that are RDFS):

~~~~~~~~
    @prefix kb:  <http://knowledgebooks.com/ontology#> .
    @prefix rdfs:  <http://www.w3.org/2000/01/rdf-schema#> .

    kb:containsCity rdfs:subPropertyOf kb:containsPlace .
    kb:containsCountry rdfs:subPropertyOf kb:containsPlace .
    kb:containsState rdfs:subPropertyOf kb:containsPlace .
~~~~~~~~

The last three lines declare that:

-   The property containsCity is a subproperty of containsPlace.

-   The property containsCountry is a subproperty of containsPlace.

-   The property containsState is a subproperty of containsPlace.

Why is this useful? For at least two reasons:

-   You can query an RDF data store for all triples that use property
    containsPlace and also match triples with property equal to
    containsCity, containsCountry, or containsState. There may not even
    be any triples that explicitly use the property containsPlace.

-   Consider a hypothetical case where you are using two different RDF
    data stores that use different properties for naming cities:
    “cityName” and “city.” You can define “cityName” to be a subproperty
    of “city” and then write all queries against the single property
    name “city.” This removes the necessity to convert data from
    different sources to use the same Schema.

In addition to providing a vocabulary for describing properties and
class membership by properties, RDFS is also used for logical inference
to infer new triples, combine data from different RDF data sources, and
to allow effective querying of RDF data stores. We will see examples of
all of these features of RDFS when we start using the Sesame libraries
in the next section to perform SPARQL queries.


## The SPARQL Query Language


SPARQL is a query language used to query RDF data stores. While SPARQL
may initially look like SQL, we will see that there are some important
differences like support for RDFS and OWL inferencing (see Section
[section:owl]) and graph-based instead of relational matching
operations. We will cover the basics of SPARQL in this section and then
see more examples in Section [section:sesame] when we learn how to embed
Sesame in Java applications.

We will use the N3 format RDF file test\_data/news.n3 for the examples
in this section and in Section [section:sesame]. This file was created
automatically by spidering Reuters news stories on the news.yahoo.com
web site and automatically extracting named entities from the text of
the articles. We will see techniques for extracting named entities from
text in the [Chapter on Statistical Natural Language Processing](#statistical-nlp) and 
[Chapter on Information Gathering](#information-gathering). In this chapter we use these sample
RDF files that I have created as input from another source.

You have already seen snippets of this file in Section [section:rdfs]
and I list the entire file here for reference (edited to fit line width:
you may find the file news.n3 easier to read if you are at your computer
and open the file in a text editor so you will not be limited to what
fits on a book page):

~~~~~~~~
    @prefix kb:  <http://knowledgebooks.com/ontology#> .
    @prefix rdfs:  <http://www.w3.org/2000/01/rdf-schema#> .

    kb:containsCity rdfs:subPropertyOf kb:containsPlace .

    kb:containsCountry rdfs:subPropertyOf kb:containsPlace .

    kb:containsState rdfs:subPropertyOf kb:containsPlace .

    <http://yahoo.com/20080616/usa_flooding_dc_16 />
        kb:containsCity "Burlington" , "Denver" ,
                        "St. Paul" ," Chicago" ,
                        "Quincy" , "CHICAGO" ,
                        "Iowa City" ;
        kb:containsRegion "U.S. Midwest" , "Midwest" ;
        kb:containsCountry "United States" , "Japan" ;
        kb:containsState "Minnesota" , "Illinois" , 
                         "Mississippi" , "Iowa" ;
        kb:containsOrganization "National Guard" ,
                         "U.S. Department of Agriculture" ,
                         "White House" ,
                         "Chicago Board of Trade" ,
                         "Department of Transportation" ;
        kb:containsPerson "Dena Gray-Fisher" ,
                          "Donald Miller" ,
                          "Glenn Hollander" ,
                          "Rich Feltes" ,
                          "George W. Bush" ;
        kb:containsIndustryTerm "food inflation" , "food" ,
                                "finance ministers" ,
                                "oil" .

    <http://yahoo.com/78325/ts_nm/usa_politics_dc_2 />
        kb:containsCity "Washington" , "Baghdad" ,
                        "Arlington" , "Flint" ;
        kb:containsCountry "United States" ,
                           "Afghanistan" ,
                           "Iraq" ;
        kb:containsState "Illinois" , "Virginia" ,
                         "Arizona" , "Michigan" ;
        kb:containsOrganization "White House" ,
                                "Obama administration" ,
                                "Iraqi government" ;
        kb:containsPerson "David Petraeus" ,
                          "John McCain" ,
                          "Hoshiyar Zebari" ,
                          "Barack Obama" ,
                          "George W. Bush" ,
                          "Carly Fiorina" ;
        kb:containsIndustryTerm "oil prices" .

    <http://yahoo.com/10944/ts_nm/worldleaders_dc_1 />
        kb:containsCity "WASHINGTON" ;
        kb:containsCountry "United States" , "Pakistan" ,
                           "Islamic Republic of Iran" ;
        kb:containsState "Maryland" ;
        kb:containsOrganization "University of Maryland" ,
                                "United Nations" ;
        kb:containsPerson "Ban Ki-moon" , "Gordon Brown" ,
                          "Hu Jintao" , "George W. Bush" ,
                          "Pervez Musharraf" ,
                          "Vladimir Putin" ,
                          "Steven Kull" ,
                          "Mahmoud Ahmadinejad" .

    <http://yahoo.com/10622/global_economy_dc_4 />
        kb:containsCity "Sao Paulo" , "Kuala Lumpur" ;
        kb:containsRegion "Midwest" ;
        kb:containsCountry "United States" , "Britain" ,
                           "Saudi Arabia" , "Spain" ,
                           "Italy" , India" , 
                           ""France" , "Canada" ,
                           "Russia" , "Germany" , "China" ,
                           "Japan" , "South Korea" ;
        kb:containsOrganization "Federal Reserve Bank" ,
                                "European Union" ,
                                "European Central Bank" ,
                                "European Commission" ;
        kb:containsPerson "Lee Myung-bak" , "Rajat Nag" ,
                          "Luiz Inacio Lula da Silva" ,
                          "Jeffrey Lacker" ;
        kb:containsCompany "Development Bank Managing" ,
                           "Reuters" ,
                           "Richmond Federal Reserve Bank" ;
        kb:containsIndustryTerm "central bank" , "food" ,
                                "energy costs" ,
                                "finance ministers" ,
                                "crude oil prices" ,
                                "oil prices" ,
                                "oil shock" ,
                                "food prices" ,
                                "Finance ministers" ,
                                "Oil prices" , "oil" .
~~~~~~~~

In the following examples, we will look at queries but not the results.
Please be patient: these same queries are used in the embedded Java
examples in the next section so it makes sense to only list the query
return values in one place. Besides that, you will enjoy running the
example programs yourself and experiment with modifying the queries.

We will start with a simple SPARQL query for subjects (news article
URLs) and objects (matching countries) with the value for the predicate
equal to $containsCountry$:

~~~~~~~~
    SELECT ?subject ?object
      WHERE {
        ?subject
        http://knowledgebooks.com/ontology#containsCountry>
        ?object .
      }
~~~~~~~~

Variables in queries start with a question mark character and can have
any names. We can make this query easier and reduce the chance of
misspelling errors by using a namespace prefix:

~~~~~~~~
    PREFIX kb:  <http://knowledgebooks.com/ontology#>
    SELECT ?subject ?object
      WHERE {
          ?subject kb:containsCountry ?object .
      }
~~~~~~~~

We could have filtered on any other predicate, for instance
$containsPlace$. Here is another example using a match against a string
literal to find all articles exactly matching the text “Maryland.” The
following queries were copied from Java source files and were embedded
as string literals so you will see quotation marks backslash escaped in
these examples. If you were entering these queries into a query form you
would not escape the quotation marks.

~~~~~~~~
    PREFIX kb: <http://knowledgebooks.com/ontology#>
       SELECT ?subject
       WHERE { ?subject kb:containsState \"Maryland\" . }
~~~~~~~~

We can also match partial string literals against regular expressions:

~~~~~~~~
    PREFIX kb:  
    SELECT ?subject ?object
       WHERE {
         ?subject
         kb:containsOrganization
         ?object FILTER regex(?object, \"University\") .
       }
~~~~~~~~

Prior to this last example query we only requested that the query return
values for subject and predicate for triples that matched the query.
However, we might want to return all triples whose subject (in this case
a news article URI) is in one of the matched triples. Note that there
are two matching triples, each terminated with a period:

~~~~~~~~
    PREFIX kb: <http://knowledgebooks.com/ontology#>
    SELECT ?subject ?a_predicate ?an_object
       WHERE {
        ?subject
        kb:containsOrganization
        ?object FILTER regex(?object, \"University\") .

        ?subject ?a_predicate ?an_object .
       }
       DISTINCT
       ORDER BY ?a_predicate  ?an_object
       LIMIT 10
       OFFSET 5
~~~~~~~~

When WHERE clauses contain more than one triple pattern to match, this
is equivalent to a Boolean “and” operation. The DISTINCT clause removes
duplicate results. The ORDER BY clause sorts the output in alphabetical
order: in this case first by predicate (containsCity, containsCountry,
etc.) and then by object. The LIMIT modifier limits the number of
results returned and the OFFSET modifier sets the number of matching
results to skip.

We are finished with our quick tutorial on using the SELECT query form.
There are three other query forms that I am not covering in this
chapter:

-   CONSTRUCT – returns a new RDF graph of query results

-   ASK – returns Boolean true or false indicating if a query matches
    any triples

-   DESCRIBE – returns a new RDF graph containing matched resources


## Using Sesame


Sesame is a complete Java library for developing RDF/RDFS applications
and we will use it in this chapter. Currently Sesame’s support for OWL
(see Section [section:owl]) is limited. Other Java libraries I have used
that more fully support OWL are Jena, OWLAPI, and the Protege library.

Figure [fig:SPARQL-util-UML] shows a UML diagram for the wrapper
classes and interface that I wrote for Sesame to make it easier for you
to get started. My wrapper uses an in-memory RDF repository that
supports inference, loading RDF/RDFS/OWL files, and performing queries.
If you decide to use Semantic Web technologies in your development you
will eventually want to use the full Sesame APIs for programatically
creating new RDF triples, finer control of the type of repository
(options are in-memory, disk based, and database) and inferencing, and
programatically using query results. That said, using my wrapper library
is a good place for you to start to start experimenting.

The class constructor $TripleStoreSesameManager$ opens a new in-memory
RDF triple store. I will not cover the internal implementation of the
classes and interface seen in Figure [fig:SPARQL-util-UML] but you can
read the source code in the subdirectory src-semantic-web.


{#SPARQL-util-UML}
![UML Class Diagram for Sesame Wrapper Classes](images/SPARQL_util_UML.png)

We will look in some detail at an example program that uses Sesame and
my wrapper library for Sesame. The source code for this example is in
the file ExampleSparqlQueries.java. This example class implements the
$ISparqlProcessResults$ interface:

~~~~~~~~
    public class ExampleSparqlQueries
           implements ISparqlProcessResults {
~~~~~~~~

and does this by defining the method:

~~~~~~~~
        public void processResult(List<String> data) {
           System.out.print("next result: "); 
           for (String s : data)
               System.out.print("|"+s+"|" + "\t  ");
           System.out.println(" . ");
        }
~~~~~~~~

that simply prints out the subject, predicate, and object of each
matched triple. The class $TripleStoreSesameManager$ method

~~~~~~~~
       public String doSparqlQuery(String sparql_query,
                                   ISparqlProcessResults
                                   handler) {
~~~~~~~~

calls a defined $processResult$ method once for each triple that matches
a query. The $ExampleSparqlQueries$ class makes several SPARQL queries
and prints the results. These queries are the example queries from the
last section. Here is an example query with the program output:

~~~~~~~~
    TripleStoreSesameManager ts =
            new TripleStoreSesameManager();
    ts.loadRDF("test_data/news.n3");
    sparql_query =
      "PREFIX kb: <http://knowledgebooks.com/ontology#>" +
      "SELECT ?subject "+
      "WHERE { ?subject kb:containsState \"Maryland\" . }";
    ts.doSparqlQuery(sparql_query, this);
~~~~~~~~

Here is the single line of output (Sesame debug printout is not shown
and the long line is split into two lines to fit the page width):

~~~~~~~~
    next result: |http://news.yahoo.com/s/nm/ \\
                  20080616/ts_nm/worldleaders_trust_dc_1 /|
~~~~~~~~

Other queries in the last section return two or three values per result;
this example only returns the subject (article URL). You can run the
text program implemented in the class $ExampleSparqlQueries$ to see all
of the query results for the examples in the last section.

There is a lot more to RDFS than what I have covered so far in this
chapter but I believe you have a sufficient introduction in order to use
the example programs to experiment with using RDF and RDFS to define
data and use Sesame in an imbedded mode in your java applications.


## OWL: The Web Ontology Language  {#owl}


We have already seen a few examples of using RDFS to define
sub-properties in the this chapter. The Web Ontology Language (OWL)
extends the expressive power of RDFS. We will not cover OWL programming
examples in this book but this section will provide some background
material. Sesame version 2.1 included in the ZIP file for this book does
not support OWL DL reasoning “out of the box.” When I need to use OWL DL
reasoning in Java applications I use one or more of the following:

-   ProtegeOwlApis – compatible with the Protege Ontology editor

-   Pellet – DL reasoner

-   Owlim – OWL DL reasoner compatible with some versions of Sesame

-   Jena – General purpose library

-   OWLAPI – a simpler API using many other libraries

-   Stardog - a commercial OWL and RDF reasoning system and datastore

-   Allegrograph - a commercial RDF+ and RDF reasoning system and datastore


OWL is more expressive than RDFS in that it supports cardinality, richer
class relationships, and Descriptive Logic (DL) reasoning. OWL treats
the idea of classes very differently than object oriented programming
languages like Java and Smalltalk, but similar to the way PowerLoom
(see [Chapter on Reasoning](#reasoning)) uses concepts (PowerLoom’s rough
equivalent to a class). In OWL instances of a class are referred to as
individuals and class membership is determined by a set of properties
that allow a DL reasoner to infer class membership of an individual
(this is called entailment.)

We saw an example of expressing transitive relationships when we were
using PowerLoom in Section [section:running~p~owerloom] where we defined
a PowerLoom rule to express that the relation “contains” is transitive.
We will now look at a similar example using OWL.

We have been using the RDF file news.n3 in previous examples and we will
layer new examples by adding new triples that represent RDF, RDFS, and
OWL. We saw in news.n3 the definition of three triples using
rdfs:subPropertyOf properties to create a more general kb:containsPlace
property:

~~~~~~~~
    kb:containsCity rdfs:subPropertyOf kb:containsPlace .
    kb:containsCountry rdfs:subPropertyOf kb:containsPlace .
    kb:containsState rdfs:subPropertyOf kb:containsPlace .

    kb:containsPlace rdf:type owl:transitiveProperty .

    kbplace:UnitedStates kb:containsState kbplace:Illinois .
    kbplace:Illinois kb:containsCity kbplace:Chicago .
~~~~~~~~

We can also infer that:

~~~~~~~~
    kbplace:UnitedStates kb:containsPlace kbplace:Chicago .
~~~~~~~~

We can also model inverse properties in OWL. For example, here we add an
inverse property kb:containedIn, adding it to the example in the last
listing:

~~~~~~~~
    kb:containedIn owl:inverseOf kb:containsPlace .
~~~~~~~~

Given an RDF container that supported extended OWL DL SPARQL queries, we
can now execute SPARQL queries matching the property kb:containedIn and
“match” triples in the RDF triple store that have never been asserted.

OWL DL is a very large subject and OWL is an even larger subject. From
reading Chapter [chapter:reasoning] and the very light coverage of OWL
in this section, you should understand the concept of class membership
not by explicitly stating that an object (or individual) is a member of
a class, but rather because an individual has properties that can be
used to infer class membership.

The World Wide Web Consortium has defined three versions of the OWL
language that are in increasing order of complexity: OWL Lite, OWL DL,
and OWL Full. OWL DL (supports Description Logic) is the most widely
used (and recommended) version of OWL. OWL Full is not computationally
decidable since it supports full logic, multiple class inheritance, and
other things that probably make it computationally intractable for all
but small problems.

Knowledge Representation and REST
---------------------------------

A theme in this book is representing knowledge using logic, expert
system rules, relational databases (supporting at the physical model
level conceptual models like entity relation), and in flexible data
models like RDF and RDFS (supporting higher level conceptual models in
OWL).

I want to make some comments about the REST architectural style and how
it is complementary to distributed knowledge representation on the web.
The REST model implies that resource providers have some internal model
for the storage and maintenance of data but use a possibly different
representation of their internal data model to transfer their internal
data to clients.

I would argue that RDF is often a good representation for resource
providers to use for transferring data in their internal data formats to
REST clients because of its flexibility in describing both data and
relations between data. RDF is inherently a rich notation because RDFS
and OWL are themselves expressed as RDF data.

I expect that conventional data sources like relational databases and
conventional data-rich web sites will benefit from publishing REST style
interfaces using RDF as the external representation of data. We are
already seeing interesting and useful projects that utilize a data
source to publish data as RDF embedded as RDFa (an XHTML notation for
embedding RDF in XHTML web pages) and I see this as a growth area for
publishing information resources that are useful for both humans and
software agents.

Material for Further Study
--------------------------

Writing Semantic Web applications in Java is a very large topic, worthy
of an entire book. I have covered in this chapter what for my work have
been the most useful Semantic Web techniques: storing and querying RDF
and RDFS for a specific application. We will see in the
[Chapter on Information Gathering](#information-gathering) some useful techniques for gathering
semantic information from the web. Specifically, in Section
[section:open~c~alais] I briefly talk about entering semantic data from
the Open Calais system into a Sesame RDF repository.

I have already mentioned several Java libraries that support OWL
Descriptive Logic reasoning in Section [section:owl]. When the
expressive power of RDF and RDFS become insufficient for your
application you will then need to use a library supporting the OWL
language and OWL Description Logic reasoning. The combination of RDF and
RDFS is sufficient for many applications and using this simpler
technology is the right way to get started developing semantic web
applications. Because RDF and RDFS (with very few OWL features, commonly
referred to as RDFS-Plus) are easier to implement and have a smaller
learning curve, I believe that the adoption of OWL DL will be slow.

I concentrated on using Sesame in an embedded mode in Java applications
in this chapter but another common use is as an RDF repository web
service. In either case, the basic ideas of converting data to RDF,
storing RDF, and allowing SPARQL queries are the same.
