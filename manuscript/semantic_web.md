# Semantic Web {#semantic-web}

We will start with a tutorial on semantic web data standards like RDF, RDFS, and OWL, then implement a wrapper for the Apache Jena library, and finally taking a deeper dive into using OWL for reasoning about disparate data sources.

The Semantic Web is intended to provide a massive linked set of data for use by software systems just as the World Wide Web provides a massive collection of linked web pages for human reading and browsing. The Semantic Web is like the web in that anyone can generate any content that they want. This freedom to publish anything works for the web because we use our ability to understand natural language to interpret what we read – and often to dismiss material that based upon our own knowledge we consider to be incorrect.

Semantic web and linked data technologies are also useful for smaller amounts of data, an example being a Knowledge Graph containing information for a business.

The core concept for the Semantic Web is data integration and use from different sources. As we will soon see, the tools for implementing the Semantic Web are designed for encoding data and sharing data from many different sources.

I cover the semantic web in this book because I believe that semantic web technologies are complementary to AI systems for gathering and processing data on the web. As more web pages are generated by applications (as opposed to simply showing static HTML files) it becomes easier to produce both HTML for human readers and semantic data for software agents.

There are several very good Semantic Web toolkits for the Java language and platform. here we use Apache Jena because it is what I often use in my own work and I believe that it is a good starting technology for your first experiments with Semantic Web technologies. This chapter provides an incomplete coverage of Semantic Web technologies and is intended merely as a gentle introduction to a few useful techniques and how to implement those techniques in Java.

The following figure shows a layered hierarchy of data models that are used to implement Semantic Web applications. To design and implement these applications we need to think in terms of physical models (storage and access of RDF, RDFS, and perhaps OWL data), logical models (how we use RDF and RDFS to define relationships between data represented as unique URIs and string literals and how we logically combine data from different sources) and conceptual modeling (higher level knowledge representation using OWL).

{#semantic-web-data-models}
![Semantic Web Data Models](images/semantic_web_data.png)

This chapter is meant to get you interested in this technology but is not intended as a complete guide. RDF data is the bedrock of the semantic web. I am also lightly covering RDFS/OWL modeling, and Descriptive Logic Reasoners which are important topics for more advanced semantic web projects.

## Available Tools

In previous Java books using RDF, I used the open source Sesame libraries. Sesame is now called RDF4J and is part of the Eclipse organization's projects.

I decided to use the Apache Jena project in this new edition because I think Jena is slightly easier to set up a light weight development environment. When we need a local RDF server for our example code, we will use a command line version of the [Fuseki](https://jena.apache.org/documentation/fuseki2/) server. For client applications we will use the Jena library for working with RDF and performing SPARQL queries on both our local Fuseki server and also remote SPARQL endpoints (i.e., public RDF data sources with SPARQL query interfaces) like DBPedia and WikiData.

## Relational Database Model Has Problems Dealing with Rapidly Changing Data Requirements  {#rdms-problems}

When people are first introduced to Semantic Web technologies their first reaction is often something like, “I can just do that with a database.” The relational database model is an efficient way to express and work with slowly changing data models. There are some clever tools for dealing with data change requirements in the database world (ActiveRecord and migrations being a good example) but it is awkward to have end users and even developers tagging on new data attributes to relational database tables.

This same limitation also applies to object oriented programming and object modeling. Even with dynamic languages that facilitate modifying classes at runtime, the options for adding attributes to existing models is just too limiting. The same argument can be made against the use of XML constrained by conformance to either DTDs or XML Schemas. It is true that RDF and RDFS can be serialized to XML using many pre existing XML namespaces for different knowledge sources and schemas but it turns out that this is done in a way that does not reduce the flexibility for extending data models. XML storage is really only a serialization of RDF and many developers who are just starting to use Semantic Web technologies initially get confused trying to read XML serialization of RDF – almost like trying to read a PDF file with a plain text editor and something to be avoided. We will use the Turtle and N3 formats that are simpler to read and understand.

A major goal for the rest of this chapter is convincing you that modeling data with RDF and RDFS facilitates freely extending data models and also allows fairly easy integration of data from different sources using different schemas without explicitly converting data from one schema to another for reuse.

## RDF: The Universal Data Format

The Resource Description Framework (RDF) is used to encode information and the RDF Schema (RDFS) facilitates using data with different RDF encodings without the need to convert data formats.

RDF data was originally encoded as XML and intended for automated processing. In this chapter we will use two simple to read formats called "N-Triples" and "N3." Sesame can be used to convert between all RDF formats so we might as well use formats that are easier to read and understand. RDF data consists of a set of triple values:

-   subject
-   predicate
-   object

Some of my work with Semantic Web technologies deals with processing news stories, extracting semantic information from the text, and storing it in RDF. I will use this application domain for the examples in this chapter. I deal with triples like:

-   subject: a URL (or URI) of a news article
-   predicate: a relation like "containsPerson"
-   object: a value like "Bill Clinton"

As previously mentioned, we will use either URIs or string literals as values for subjects and objects. We will always use URIs for the values of predicates. In any case URIs are usually preferred to string literals because they are unique. We will see an example of this preferred use but first we need to learn the N-Triple and N3 RDF formats.

I proposed the idea that RDF was more flexible than Object Modeling in programming languages, relational databases, and XML with schemas. If we can tag new attributes on the fly to existing data, how do we prevent what I might call “data chaos” as we modify existing data sources? It turns out that the solution to this problem is also the solution for encoding real semantics (or meaning) with data: we usually use unique URIs for RDF subjects, predicates, and objects, and usually with a preference for not using string literals. I will try to make this idea more clear with some examples.

Any part of a triple (subject, predicate, or object) is either a URI or a string literal. URIs encode namespaces. For example, the containsPerson predicate in the last example could properly be written as:

{lang="sparql",linenos=off}
~~~~~~~~
http://knowledgebooks.com/ontology/#containsPerson
~~~~~~~~

The first part of this URI is considered to be the namespace for (what we will use as a predicate) “containsPerson.” When different RDF triples use this same predicate, this is some assurance to us that all users of this predicate subscribe to the same meaning. Furthermore, we will see later that we can use RDFS to state equivalency between this predicate (in the namespace http://knowledgebooks.com/ontology/) with predicates represented by different URIs used in other data sources. In an “artificial intelligence” sense, software that we write does not understand a predicate like "containsPerson" in the way that a human reader can by combining understood common meanings for the words "contains" and "person" but for many interesting and useful types of applications that is fine as long as the predicate is used consistently. We will see shortly that we can define abbreviation prefixes for namespaces which makes RDF and RDFS files shorter and easier to read.

The Jena library supports most serialization formats for RDF:

TBD: define the following:

- Turtle
- N-Triples
- NQuads
- TriG
- JSON-LD
- RDF/XML
- RDF/JSON
- TriX
- RDF Binary


A statement in N-Triple format consists of three URIs (or string literals – any combination) followed by a period to end the statement. While statements are often written one per line in a source file they can be broken across lines; it is the ending period which marks the end of a statement. The standard file extension for N-Triple format files is \*.nt,  the standard format for N3 format files is \*.n3, AND THE EXTENSTION FOR TURTLE FORMAT FILES IF \*.ttl.

My preference is to use N-Triple format files as output from programs that I write to save data as RDF. N-Triple files don't use any abbreviations but each RDF statement is self-contained. I often use tools like the command line commands in Jena or RDF4J to convert N-Triple files to N3 if I will be reading them or even hand editing them. Here is an example using the Turtle syntax:

{lang="sparql",linenos=off}
~~~~~~~~
@prefix kb:  <http://knowledgebooks.com/ontology#> .

<http://news.com/201234/> kb:containsCountry "China"  .
~~~~~~~~

The Turtle format adds abbreviations to the N-Triple format.

Here we see the use of an abbreviation prefix “kb:” for the namespace for my company KnowledgeBooks.com ontologies. The first term in the RDF statement (the subject) is the URI of a news article. The second term (the predicate) is “containsCountry” in the “kb:” namespace. The last item in the statement (the object) is a string literal “China.” I would
describe this RDF statement in English as, “The news article at URI http://news.com/201234 mentions the country China.”

This was a very simple N3 example which we will expand to show additional features of the N3 notation. As another example, consider the case if this news article also mentions the USA. Instead of adding a whole new statement like this we can combine them using Turtle notation. Here we have two separate DRF statements:

{lang="sparql",linenos=off}
~~~~~~~~
@prefix kb:  <http://knowledgebooks.com/ontology#> .

<http://news.com/201234/> kb:containsCountry "China"  .
<http://news.com/201234/> kb:containsCountry "USA"  .
~~~~~~~~

We can collapse multiple RDF statements that share the same subject and optionally the same predicate:

{lang="sparql",linenos=off}
~~~~~~~~
@prefix kb:  <http://knowledgebooks.com/ontology#> .

<http://news.com/201234/> kb:containsCountry "China" ,
                                              "USA" .
~~~~~~~~

We can also add in additional predicates that use the same subject:

{lang="sparql",linenos=off}
~~~~~~~~
@prefix kb:  <http://knowledgebooks.com/ontology#> .

<http://news.com/201234/> kb:containsCountry "China" ,
                                              "USA" .
        kb:containsOrganization "United Nations" ;
        kb:containsPerson "Ban Ki-moon" , "Gordon Brown" ,
                          "Hu Jintao" , "George W. Bush" ,
                          "Pervez Musharraf" ,
                          "Vladimir Putin" , 
                          "Mahmoud Ahmadinejad" .
~~~~~~~~

This single N3 statement represents ten individual RDF triples. Each section defining triples with the same subject and predicate have objects separated by commas and ending with a period. Please note that whatever RDF storage system we use (we will be using Sesame) it makes no difference if we load RDF as XML, N-Triple, of N3 format files: internally subject, predicate, and object triples are stored in the same way and are used in the same way.

I promised you that the data in RDF data stores was easy to extend. As an example, let us assume that we have written software that is able to read online news articles and create RDF data that captures some of the semantics in the articles. If we extend our program to also recognize dates when the articles are published, we can simply reprocess articles and for each article add a triple to our RDF data store using a form like:

{lang="sparql",linenos=off}
~~~~~~~~
<http://news.com/201234/> kb:datePublished "2008-05-11" .
~~~~~~~~

Furthermore, if we do not have dates for all news articles that is often acceptable depending on the application.

## Extending RDF with RDF Schema {#rdfs}

RDFS supports the definition of classes and properties based on set inclusion. In RDFS classes and properties are orthogonal. We will not simply be using properties to define data attributes for classes – this is different from object modeling and object oriented programming languages like Java. RDFS is encoded in RDF – the same syntax.

Because the Semantic Web is intended to be processed automatically by software systems it is encoded as RDF. There is a problem that must be solved in implementing and using the Semantic Web: everyone who publishes Semantic Web data is free to create their own RDF schemas for storing data; for example, there is usually no single standard RDF schema definition for topics like news stories and stock market data. Understanding the difficulty of integrating different data sources in different formats helps to understand the design decisions behind the Semantic Web.

We will start with an example that is an extension of the example in the last section that also uses RDFS. We add a few additional RDF statements (that are RDFS):

{lang="sparql",linenos=off}
~~~~~~~~
@prefix kb:  <http://knowledgebooks.com/ontology#> .
@prefix rdfs:  <http://www.w3.org/2000/01/rdf-schema#> .

    kb:containsCity rdfs:subPropertyOf kb:containsPlace .
    kb:containsCountry rdfs:subPropertyOf kb:containsPlace .
    kb:containsState rdfs:subPropertyOf kb:containsPlace .
~~~~~~~~

The last three lines declare that:

-   The property containsCity is a subproperty of containsPlace.
-   The property containsCountry is a subproperty of containsPlace.
-   The property containsState is a subproperty of containsPlace.

Why is this useful? For at least two reasons:

-   You can query an RDF data store for all triples that use property containsPlace and also match triples with property equal to containsCity, containsCountry, or containsState. There may not even be any triples that explicitly use the property containsPlace.

-   Consider a hypothetical case where you are using two different RDF data stores that use different properties for naming cities: “cityName” and “city.” You can define “cityName” to be a subproperty of “city” and then write all queries against the single property name “city.” This removes the necessity to convert data from different sources to use the same Schema.

In addition to providing a vocabulary for describing properties and class membership by properties, RDFS is also used for logical inference to infer new triples, combine data from different RDF data sources, and to allow effective querying of RDF data stores. We will see examples of all of these features of RDFS when we start using the Sesame libraries in the next section to perform SPARQL queries.


## The SPARQL Query Language

SPARQL is a query language used to query RDF data stores. While SPARQL may initially look like SQL, we will see that there are some important differences like support for RDFS and OWL inferencing (see Section [section:owl]) and graph-based instead of relational matching operations. We will cover the basics of SPARQL in this section and then see more examples in Section [section:sesame] when we learn how to embed Sesame in Java applications.

We will use the N3 format RDF file test\_data/news.n3 for the examples in this section and in Section [section:sesame]. This file was created
automatically by the process of spidering Reuters news stories on the news.yahoo.com web site and automatically extracting named entities from the text of the articles. We will see techniques for extracting named entities from text in the chapter on Natural Language Processing and the chapter on Information Gathering. In this chapter we use these sample RDF files that I have created as input from another source.

You have already seen snippets of this file and I list the entire file here for reference (edited to fit line width: you may find the file news.n3 easier to read if you are at your computer
and open the file in a text editor so you will not be limited to what fits on a book page):

{lang="sparql",linenos=off}
~~~~~~~~
@prefix kb:  <http://knowledgebooks.com/ontology#> .
@prefix rdfs:  <http://www.w3.org/2000/01/rdf-schema#> .

kb:containsCity rdfs:subPropertyOf kb:containsPlace .

kb:containsCountry rdfs:subPropertyOf kb:containsPlace .

kb:containsState rdfs:subPropertyOf kb:containsPlace .

<http://yahoo.com/20080616/usa_flooding_dc_16/>
        kb:containsCity "Burlington" , "Denver" ,
                        "St. Paul" ," Chicago" ,
                        "Quincy" , "CHICAGO" ,
                        "Iowa City" ;
        kb:containsRegion "U.S. Midwest" , "Midwest" ;
        kb:containsCountry "United States" , "Japan" ;
        kb:containsState "Minnesota" , "Illinois" , 
                         "Mississippi" , "Iowa" ;
        kb:containsOrganization "National Guard" ,
                         "U.S. Department of Agriculture" ,
                         "White House" ,
                         "Chicago Board of Trade" ,
                         "Department of Transportation" ;
        kb:containsPerson "Dena Gray-Fisher" ,
                          "Donald Miller" ,
                          "Glenn Hollander" ,
                          "Rich Feltes" ,
                          "George W. Bush" ;
        kb:containsIndustryTerm "food inflation" , "food" ,
                                "finance ministers" ,
                                "oil" .

<http://yahoo.com/78325/ts_nm/usa_politics_dc_2/>
        kb:containsCity "Washington" , "Baghdad" ,
                        "Arlington" , "Flint" ;
        kb:containsCountry "United States" ,
                           "Afghanistan" ,
                           "Iraq" ;
        kb:containsState "Illinois" , "Virginia" ,
                         "Arizona" , "Michigan" ;
        kb:containsOrganization "White House" ,
                                "Obama administration" ,
                                "Iraqi government" ;
        kb:containsPerson "David Petraeus" ,
                          "John McCain" ,
                          "Hoshiyar Zebari" ,
                          "Barack Obama" ,
                          "George W. Bush" ,
                          "Carly Fiorina" ;
        kb:containsIndustryTerm "oil prices" .

<http://yahoo.com/10944/ts_nm/worldleaders_dc_1/>
        kb:containsCity "WASHINGTON" ;
        kb:containsCountry "United States" , "Pakistan" ,
                           "Islamic Republic of Iran" ;
        kb:containsState "Maryland" ;
        kb:containsOrganization "University of Maryland" ,
                                "United Nations" ;
        kb:containsPerson "Ban Ki-moon" , "Gordon Brown" ,
                          "Hu Jintao" , "George W. Bush" ,
                          "Pervez Musharraf" ,
                          "Vladimir Putin" ,
                          "Steven Kull" ,
                          "Mahmoud Ahmadinejad" .

<http://yahoo.com/10622/global_economy_dc_4/>
        kb:containsCity "Sao Paulo" , "Kuala Lumpur" ;
        kb:containsRegion "Midwest" ;
        kb:containsCountry "United States" , "Britain" ,
                           "Saudi Arabia" , "Spain" ,
                           "Italy" , India" , 
                           ""France" , "Canada" ,
                           "Russia" , "Germany" , "China" ,
                           "Japan" , "South Korea" ;
        kb:containsOrganization "Federal Reserve Bank" ,
                                "European Union" ,
                                "European Central Bank" ,
                                "European Commission" ;
        kb:containsPerson "Lee Myung-bak" , "Rajat Nag" ,
                          "Luiz Inacio Lula da Silva" ,
                          "Jeffrey Lacker" ;
        kb:containsCompany "Development Bank Managing" ,
                           "Reuters" ,
                           "Richmond Federal Reserve Bank" ;
        kb:containsIndustryTerm "central bank" , "food" ,
                                "energy costs" ,
                                "finance ministers" ,
                                "crude oil prices" ,
                                "oil prices" ,
                                "oil shock" ,
                                "food prices" ,
                                "Finance ministers" ,
                                "Oil prices" , "oil" .
~~~~~~~~

In the following examples, we will use the main method in the class **JenaApi** that allows us to load multiple RDF input files and then to interactively enter SPARQL queries.

We will start with a simple SPARQL query for subjects (news article URLs) and objects (matching countries) with the value for the predicate equal to **containsCountry**:

{lang="sparql",linenos=off}
~~~~~~~~
SELECT ?subject ?object
      WHERE {
        ?subject
        <http://knowledgebooks.com/ontology#containsCountry>
        ?object .
}
~~~~~~~~

Variables in queries start with a question mark character and can have any names. We can make this query easier and reduce the chance of misspelling errors by using a namespace prefix:

{lang="sparql",linenos=off}
~~~~~~~~
PREFIX kb:  <http://knowledgebooks.com/ontology#>
SELECT ?subject ?object
  WHERE {
      ?subject kb:containsCountry ?object .
  }
~~~~~~~~

**Using the command line option in the Jena wrapper example**

We will later implement the Java class **JenaApis**. You can run the method **main** in the Java class **JenaApis** using the following to load RDF input files and interactively make SPARQL queries against the RDF data in the input files:

{lang="bash",linenos=on}
~~~~~~~~
$ mvn exec:java -Dexec.mainClass="com.markwatson.semanticweb.JenaApis" \
               -Dexec.args="data/news.n3 data/sample_news.nt"
~~~~~~~~

The command line argument in line 3 starting with **-Dexec.args=** is one way to pass command line arguments to the method **main**. The backslash character at the end of line 2 is the way to continue a long command line request in bash or zsh.

Here is an interactive example of the last SPARQL example:

{lang="bash",linenos=off}
~~~~~~~~
$ mvn exec:java -Dexec.mainClass="com.markwatson.semanticweb.JenaApis" \
               -Dexec.args="data/news.n3"

Multiple queries are OK.
Enter a blank line to process query.
Enter a SPARQL query:
PREFIX kb:  <http://knowledgebooks.com/ontology#>
SELECT ?subject ?object
  WHERE {
      ?subject kb:containsCountry ?object .
  }

[QueryResult vars:[subject, object]
Rows:
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, Russia]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/usa_flooding_dc_16/, Japan]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, India]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, United States]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/usa_politics_dc_2/, Afghanistan]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, Saudi Arabia]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, United States]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, France]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/usa_politics_dc_2/, Iraq]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, Pakistan]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, Spain]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, Italy]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, Islamic Republic of Iran]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, Canada]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, Britain]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/usa_politics_dc_2/, United States]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, South Korea]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, Germany]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/usa_flooding_dc_16/, United States]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, China]
	[http://news.yahoo.com/s/nm/20080616/bs_nm/global_economy_dc_4/, Japan]

Enter a SPARQL query:
~~~~~~~~

We could have filtered on any other predicate, for instance **containsPlace**. Here is another example using a match against a string literal to find all articles exactly matching the text “Maryland.”

{lang="sparql",linenos=off}
~~~~~~~~
PREFIX kb:  <http://knowledgebooks.com/ontology#>
SELECT ?subject WHERE { ?subject kb:containsState "Maryland" . }
~~~~~~~~

The output is:

{lang="bash",linenos=off}
~~~~~~~~
Enter a SPARQL query:
PREFIX kb:  <http://knowledgebooks.com/ontology#>
SELECT ?subject WHERE { ?subject kb:containsState "Maryland" . }

[QueryResult vars:[subject]
Rows:
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/]
~~~~~~~~

We can also match partial string literals against regular expressions:

{lang="sparql",linenos=off}
~~~~~~~~
PREFIX kb: <http://knowledgebooks.com/ontology#>
SELECT ?subject ?object
       WHERE {
         ?subject
         kb:containsOrganization
         ?object FILTER regex(?object, "University") .
       }
~~~~~~~~

The output is:

{lang="bash",linenos=off}
~~~~~~~~
Enter a SPARQL query:
PREFIX kb: <http://knowledgebooks.com/ontology#>
SELECT ?subject ?object
       WHERE {
         ?subject
         kb:containsOrganization
         ?object FILTER regex(?object, "University") .
       }

[QueryResult vars:[subject, object]
Rows:
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, University of Maryland]
~~~~~~~~

Prior to this last example query we only requested that the query returnvalues for subject and predicate for triples that matched the query.
However, we might want to return all triples whose subject (in this case a news article URI) is in one of the matched triples. Note that there are two matching triples, each terminated with a period:

{lang="sparql",linenos=off}
~~~~~~~~
PREFIX kb: <http://knowledgebooks.com/ontology#>
SELECT DISTINCT ?subject ?a_predicate ?an_object
 WHERE {
    ?subject kb:containsOrganization ?object FILTER regex(?object,"University") .
    ?subject ?a_predicate ?an_object .
}
ORDER BY ?a_predicate ?an_object
LIMIT 10
OFFSET 5
~~~~~~~~

When WHERE clauses contain more than one triple pattern to match, this is equivalent to a Boolean “and” operation. The DISTINCT clause removes duplicate results. The ORDER BY clause sorts the output in alphabetical order: in this case first by predicate (containsCity, containsCountry, etc.) and then by object. The LIMIT modifier limits the number of results returned and the OFFSET modifier sets the number of matching results to skip.

The output is:

{lang="bash",linenos=off}
~~~~~~~~
Enter a SPARQL query:
PREFIX kb: <http://knowledgebooks.com/ontology#>
SELECT DISTINCT ?subject ?a_predicate ?an_object
 WHERE {
    ?subject kb:containsOrganization ?object FILTER regex(?object,"University") .
    ?subject ?a_predicate ?an_object .
}
ORDER BY ?a_predicate ?an_object
LIMIT 10
OFFSET 5

[QueryResult vars:[subject, a_predicate, an_object]
Rows:
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsOrganization, University of Maryland]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsPerson, Ban Ki-moon]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsPerson, George W. Bush]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsPerson, Gordon Brown]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsPerson, Hu Jintao]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsPerson, Mahmoud Ahmadinejad]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsPerson, Pervez Musharraf]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsPerson, Steven Kull]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsPerson, Vladimir Putin]
	[http://news.yahoo.com/s/nm/20080616/ts_nm/worldleaders_trust_dc_1/, http://knowledgebooks.com/ontology#containsState, Maryland]
~~~~~~~~


We are finished with our quick tutorial on using the SELECT query form. There are three other query forms that I am not covering in this chapter:

-   CONSTRUCT – returns a new RDF graph of query results

-   ASK – returns Boolean true or false indicating if a query matches
    any triples

-   DESCRIBE – returns a new RDF graph containing matched resources


## Using Jena

Apache Jena is a complete Java library for developing RDF/RDFS applications and we will use it in this chapter. Other available libraries that we don't use here are RDF4J (used to be Sesame), OWLAPI, AllegroGraph, and the Protege library.

The following figure shows a UML diagram for the wrapper classes and interface that I wrote for Jena to make it easier for you to get started. My wrapper uses an in-memory RDF repository that supports inference, loading RDF/RDFS/OWL files, and performing queries. If you decide to use Semantic Web technologies in your development you will eventually want to use the full Sesame APIs for programmatically creating new RDF triples, finer control of the type of repository (options are in-memory, disk based, and database) and inferencing, and programmatically using query results. That said, using my wrapper library is a good place for you to start to start experimenting.

The class constructor **JenaApis** opens a new in-memory RDF triple store.

![UML Class Diagram for Apache Jena Wrapper Classes](images/jenaapis-uml.png)

We will look in some detail at the code in this UML Class Diagram. To improve portability to alternative RDF libraries, I wrote two wrapper classes for Jena, one class to represent query results and the other to wrap the Jena APIs that I use.


TBD


![Example query in the unit test class](images/jena-ide-sparql-example.png)

TBD

### Java Wrapper for Jena APIs and an Example

For portability to other RDF and semantic web libraries, when we wrap the Jena APIs we want the results to be in standard Java data classes. The following listing shows the class **QueryResult** that contains the variables used in a SPARQL query and a list or rows containing matched value bindings for these variables:

{lang="java",linenos=on}
~~~~~~~~
package com.markwatson.semanticweb;

import java.util.ArrayList;
import java.util.List;

public class QueryResult {
  private QueryResult() { }
  public QueryResult(List<String> variableList) {
    this.variableList = variableList;
  }
  public List<String> variableList;
  public List<List<String>> rows = new ArrayList();
  public String toString() {
    StringBuilder sb = new StringBuilder("[QueryResult vars:" + variableList +
                  "\nRows:\n");
    for (List<String> row : rows) {
      sb.append("\t" + row + "\n");
    }
    return sb.toString();
  }
}
~~~~~~~~

I defined a **toString** method so when you print an instance of the class QueryResult** you see the contained data.

The following listing shows the wrapper class **JenaApis**:

{lang="java",linenos=on}
~~~~~~~~
package com.markwatson.semanticweb;

import org.apache.jena.query.*;
import org.apache.jena.rdf.model.*;
import org.apache.jena.riot.RDFDataMgr;
import org.apache.jena.riot.RDFFormat;

import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

public class JenaApis {

  public JenaApis() {
    model = ModelFactory.createDefaultModel();
  }

  public Model model() {
    return model;
  }

  public void loadRdfFile(String fpath) {
    model.read(fpath);
  }

  public void saveModelToTurtleFormat(String outputPath) throws IOException {
    FileOutputStream fos = new FileOutputStream(outputPath);
    RDFDataMgr.write(fos, model, RDFFormat.TRIG_PRETTY);
    fos.close();
  }
  public void saveModelToN3Format(String outputPath) throws IOException {
    FileOutputStream fos = new FileOutputStream(outputPath);
    RDFDataMgr.write(fos, model, RDFFormat.NTRIPLES);
    fos.close();
  }

  public QueryResult query(String sparqlQuery) {
    Query query = QueryFactory.create(sparqlQuery);
    QueryExecution qexec = QueryExecutionFactory.create(query, model);
    ResultSet results = qexec.execSelect();
    QueryResult qr = new QueryResult(results.getResultVars());
    for (; results.hasNext(); ) {
      QuerySolution solution = results.nextSolution();
      List<String> newResultRow = new ArrayList();
      for (String var : qr.variableList) {
        newResultRow.add(solution.get(var).toString());
      }
      qr.rows.add(newResultRow);
    }
    return qr;
  }

  private Model model;

  public static void main(String[] args) {
    /*
    Execute using, for example:
         mvn exec:java -Dexec.mainClass="com.markwatson.semanticweb.JenaApis" -Dexec.args="data/news.n3"
     */
    JenaApis ja = new JenaApis();
    System.out.println(args.length);
    if (args.length == 0) {
      // no RDF input file names on command line so use a default file:
      ja.loadRdfFile("data/news.n3");
    } else {
      for (String fpath : args) {
        ja.loadRdfFile(fpath);
      }
    }
    System.out.println("Multiple queries are OK.");
    System.out.println("Enter a blank line to process query.");
    while (true) {
      System.out.println("Enter a SPARQL query:");
      Scanner sc = new Scanner(System.in);
      StringBuilder sb = new StringBuilder();
      while (sc.hasNextLine()) {  //until no other inputs to proceed
        String s = sc.nextLine();
        if (s.equals("quit") || s.equals("QUIT") || s.equals("exit") || s.equals("EXIT"))
          System.exit(0);
        if (s.length() < 1) break;
        sb.append(s);
        sb.append("\n");
      }
      QueryResult qr = ja.query(sb.toString());
      System.out.println(qr);
    }
  }
}
~~~~~~~~

TBD

The following class shows the unit test class **JenaApisTest**:

{lang="java",linenos=on}
~~~~~~~~
package com.markwatson.semanticweb;

import junit.framework.Test;
import junit.framework.TestCase;
import junit.framework.TestSuite;

public class JenaApisTest extends TestCase {
  /**
   * Create the test case
   *
   * @param testName name of the test case
   */
  public JenaApisTest(String testName)
  {
    super( testName );
  }

  /**
   * @return the suite of tests being tested
   */
  public static Test suite()
  {
    return new TestSuite( JenaApisTest.class );
  }

  /**
   * Test that is just for side effect printouts:
   */
  public void test1() throws Exception {
    JenaApis jenaApis = new JenaApis();
    jenaApis.loadRdfFile("data/rdfs_business.nt");
    jenaApis.loadRdfFile("data/sample_news.nt");
    jenaApis.loadRdfFile("data/sample_news.n3");

    QueryResult qr = jenaApis.query(
        "select ?s ?o where { ?s <http://knowledgebooks.com/title> ?o } limit 15");
    System.out.println("qr:" + qr);

    jenaApis.saveModelToTurtleFormat("model_save.nt");
    jenaApis.saveModelToN3Format("model_save.n3");
  }

}
~~~~~~~~

TBD

## OWL: The Web Ontology Language  {#owl}


We have already seen a few examples of using RDFS to define
sub-properties in the this chapter. The Web Ontology Language (OWL) extends the expressive power of RDFS. We will not cover OWL programming examples in this book but this section will provide some background material. The following RDF data stores support at lease some level of OWL reasoning:

-   ProtegeOwlApis – compatible with the Protege Ontology editor
-   Pellet – DL reasoner
-   Owlim – OWL DL reasoner compatible with some versions of Sesame
-   Jena – General purpose library
-   OWLAPI – a simpler API using many other libraries
-   Stardog - a commercial OWL and RDF reasoning system and datastore
-   Allegrograph - a commercial RDF+ and RDF reasoning system and datastore


OWL is more expressive than RDFS in that it supports cardinality, richer class relationships, and Descriptive Logic (DL) reasoning. OWL treats the idea of classes very differently than object oriented programming languages like Java and Smalltalk, but similar to the way PowerLoom (see chapter on *Reasoning*) uses concepts (PowerLoom’s rough equivalent to a class). In OWL instances of a class are referred to as individuals and class membership is determined by a set of properties that allow a DL reasoner to infer class membership of an individual (this is called entailment.)

We saw an example of expressing transitive relationships when we were using PowerLoom in the chapter on *Reasoning* where we defined a PowerLoom rule to express that the relation “contains” is transitive. We will now look at a similar example using OWL.

We have been using the RDF file news.n3 in previous examples and we will layer new examples by adding new triples that represent RDF, RDFS, and OWL. We saw in news.n3 the definition of three triples using rdfs:subPropertyOf properties to create a more general kb:containsPlace property:

{lang="sparql",linenos=off}
~~~~~~~~
kb:containsCity rdfs:subPropertyOf kb:containsPlace .
kb:containsCountry rdfs:subPropertyOf kb:containsPlace .
kb:containsState rdfs:subPropertyOf kb:containsPlace .

kb:containsPlace rdf:type owl:transitiveProperty .

kbplace:UnitedStates kb:containsState kbplace:Illinois .
kbplace:Illinois kb:containsCity kbplace:Chicago .
~~~~~~~~

We can also infer that:

{lang="sparql",linenos=off}
~~~~~~~~
kbplace:UnitedStates kb:containsPlace kbplace:Chicago .
~~~~~~~~

We can also model inverse properties in OWL. For example, here we add an
inverse property kb:containedIn, adding it to the example in the last
listing:

{lang="sparql",linenos=off}
~~~~~~~~
kb:containedIn owl:inverseOf kb:containsPlace .
~~~~~~~~

Given an RDF container that supported extended OWL DL SPARQL queries, we can now execute SPARQL queries matching the property kb:containedIn and “match” triples in the RDF triple store that have never been asserted.

OWL DL is a very large subject and OWL is an even larger subject. From reading chapter on Reasoning and the very light coverage of OWL in this section, you should understand the concept of class membership not by explicitly stating that an object (or individual) is a member of a class, but rather because an individual has properties that can be used to infer class membership.

The World Wide Web Consortium has defined three versions of the OWL language that are in increasing order of complexity: OWL Lite, OWL DL, and OWL Full. OWL DL (supports Description Logic) is the most widely used (and recommended) version of OWL. OWL Full is not computationally decidable since it supports full logic, multiple class inheritance, and other things that probably make it computationally intractable for all but small problems.

## Semantic Web Wrap-up

Writing Semantic Web applications in Java is a very large topic, worthy of an entire book. I have covered in this chapter what for my work have been the most useful Semantic Web techniques: storing and querying RDF and RDFS for a specific application. We will see in later chapters the use of RDF for automatically creating Knowledge Graphs and for automatic navigation of Knowledge Graphs.
